{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "import os\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:6,0:9].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob(r'I:\\20200729_selected\\*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: 27\n"
     ]
    }
   ],
   "source": [
    "print(\"images: \" + str(len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/27\n",
      "1/27\n",
      "2/27\n",
      "3/27\n",
      "4/27\n",
      "5/27\n",
      "6/27\n",
      "7/27\n",
      "8/27\n",
      "9/27\n",
      "10/27\n",
      "11/27\n",
      "12/27\n",
      "13/27\n",
      "14/27\n",
      "15/27\n",
      "16/27\n",
      "17/27\n",
      "18/27\n",
      "19/27\n",
      "20/27\n",
      "21/27\n",
      "22/27\n",
      "23/27\n",
      "24/27\n",
      "25/27\n",
      "26/27\n"
     ]
    }
   ],
   "source": [
    "for idx,fname in enumerate(images):  # Here, 10 can be changed to whatever number you like to choose\n",
    "    img = cv2.imread(fname) # Capture frame-by-frame\n",
    "    #print(images[im_i])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (6,9), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)   # Certainly, every loop objp is the same, in 3D.\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (7,7), corners2, ret)\n",
    "        found += 1\n",
    "#         cv2.imshow('img', img)\n",
    "#         plt.imshow(img)\n",
    "    print(str(idx) + \"/\" + str(len(images)))\n",
    "    # calibration\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None,flags = cv2.CALIB_RATIONAL_MODEL )\n",
    "\n",
    "# transform the matrix and distortion coefficients to writable lists\n",
    "data = {'camera_matrix': np.asarray(mtx).tolist(),\n",
    "        'dist_coeff': np.asarray(dist).tolist()}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 170 images\n",
    "camera_matrix = [[4366.468147544356, 0.0, 698.9532053912084],[0.0, 3789.561942373732, 592.5073990607239],[0.0, 0.0, 1.0]],\n",
    "dist_coeff = [[-8.471758923036978, 746.781535878522,0.27140072223473805,0.41086929694027546,-14358.204234119692]]\n",
    "\n",
    "#Using 30 selected images\n",
    "camera_matrix = [[5362.615376027046, 0.0, 682.6981296747797],[0.0, 4845.8758318112605, 489.1564826638393],[0.0, 0.0, 1.0]],\n",
    "dist_coeff= [[-23.758139835007544,3162.4371379194113,0.23628832244369607,0.3639937905473583,-112952.65742180515]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx = np.array(camera_matrix)\n",
    "dist = np.array(dist_coeff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\convert_c.cpp:112: error: (-215:Assertion failed) src.size == dst.size && src.channels() == dst.channels() in function 'cvConvertScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-68fe23ef7653>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# frame_markers = aruco.drawDetectedMarkers(white_background.copy(), corners, ids)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjPts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimatePoseSingleMarkers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorners\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkerLength\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mimaxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawDetectedMarkers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorners\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# imaxis = aruco.drawDetectedMarkers(white_background, corners, ids)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\convert_c.cpp:112: error: (-215:Assertion failed) src.size == dst.size && src.channels() == dst.channels() in function 'cvConvertScale'\n"
     ]
    }
   ],
   "source": [
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_250)\n",
    "length_of_axis = 0.09\n",
    "markerLength = 0.18\n",
    "\n",
    "white_background  = np.full((1024, 1280, 3),255)\n",
    "# white_background = (np.float32(white_background), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "image_data = \"./img/000000000000_rendered.png\"\n",
    "frame  = cv2.imread(image_data,cv2.IMREAD_UNCHANGED)\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "parameters =  aruco.DetectorParameters_create()\n",
    "corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "\n",
    "frame_markers = aruco.drawDetectedMarkers(frame.copy(), corners, ids)\n",
    "# frame_markers = aruco.drawDetectedMarkers(white_background.copy(), corners, ids)\n",
    "\n",
    "rvecs,tvecs, objPts = aruco.estimatePoseSingleMarkers(corners, markerLength , mtx, dist)\n",
    "imaxis = aruco.drawDetectedMarkers(frame.copy(), corners, ids)\n",
    "# imaxis = aruco.drawDetectedMarkers(white_background, corners, ids)\n",
    "\n",
    "\n",
    "# for i in range(len(rvecs)):\n",
    "#     imaxis = aruco.drawAxis(imaxis, mtx, dist, rvecs[i], tvecs[i], length_of_axis)\n",
    "\n",
    "\n",
    "# # Marker data to dictionary\n",
    "# marker_dict = {}\n",
    "\n",
    "# for idx,marker_index in enumerate(ids):\n",
    "#     marker_index = marker_index[0]\n",
    "#     _vecs = {}\n",
    "#     _vecs[\"rvec\"] = rvecs[idx][0]\n",
    "#     _vecs[\"tvec\"] = tvecs[idx][0]\n",
    "#     _vecs[\"corner\"] = corners[idx][0]\n",
    "#     marker_dict[marker_index] = _vecs\n",
    "# print(\"tvecs and rvecs for each marker\\n\")\n",
    "# # pp.pprint(marker_dict)\n",
    "\n",
    "# # def annotateDistanceFromDic(idx0,idx1):\n",
    "\n",
    "# def getCenterOnImageFromDic(idx):\n",
    "#     return np.average(marker_dict[idx][\"corner\"],axis = 0)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.imshow(imaxis)\n",
    "# plt.imshow(frame_markers)\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
